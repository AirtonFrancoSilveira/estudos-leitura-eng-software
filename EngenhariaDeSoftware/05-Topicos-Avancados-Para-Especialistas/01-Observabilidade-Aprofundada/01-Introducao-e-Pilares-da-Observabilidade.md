# üìä Observabilidade e Monitoramento Distribu√≠do

## üìö **Objetivos de Aprendizagem**

Ao final deste m√≥dulo, voc√™ ser√° capaz de:

-   ‚úÖ **Diferenciar fundamentalmente Monitoramento de Observabilidade**.
-   ‚úÖ **Instrumentar uma aplica√ß√£o Java** com base nos tr√™s pilares: Logs, M√©tricas e Traces.
-   ‚úÖ **Implementar Tracing Distribu√≠do** usando OpenTelemetry para seguir uma requisi√ß√£o atrav√©s de m√∫ltiplos microservi√ßos.
-   ‚úÖ **Utilizar o AWS X-Ray** para visualizar e depurar gargalos em sistemas serverless e baseados em cont√™ineres.
-   ‚úÖ **Criar dashboards eficazes no CloudWatch** que correlacionam m√©tricas de neg√≥cio com m√©tricas de sistema.
-   ‚úÖ **Executar queries complexas com CloudWatch Logs Insights** para investigar problemas de produ√ß√£o rapidamente.

---

## üéØ **Conceito 1: Por que Monitoramento N√£o √© Suficiente**

Durante anos, o foco foi no **Monitoramento**: coletar dados pr√©-definidos (CPU, mem√≥ria, lat√™ncia) e criar alertas quando ultrapassam um limiar. Isso nos diz **SE** algo est√° errado.

A **Observabilidade** √© a evolu√ß√£o. Ela nos d√° a capacidade de **fazer perguntas arbitr√°rias sobre o nosso sistema sem precisar prever a pergunta com anteced√™ncia**. Ela nos ajuda a entender **POR QUE** algo est√° errado.

| Caracter√≠stica | Monitoramento (O QUE) | Observabilidade (PORQU√ä) |
| :--- | :--- | :--- |
| **Abordagem** | Reativa. "O sistema est√° lento?" | Proativa e Investigativa. "Quais usu√°rios espec√≠ficos est√£o vendo a maior lat√™ncia e em qual chamada de servi√ßo externa isso est√° acontecendo?"|
| **Dados** | Pr√©-agregados e conhecidos (m√©tricas e "health checks"). | Ricos, de alta cardinalidade e n√£o agregados (traces, logs estruturados). |
| **Foco** | Nos "conhecidos desconhecidos" (sabemos que a CPU pode subir). | Nos "desconhecidos desconhecidos" (erros que nunca imaginamos que poderiam ocorrer).|
| **Ferramentas** | Nagios, Zabbix, CloudWatch Alarms b√°sicos. | OpenTelemetry, AWS X-Ray, Datadog, New Relic, Honeycomb. |

Em resumo: Monitoramento √© olhar o painel do carro. Observabilidade √© ter um mec√¢nico de F√≥rmula 1 conectado ao motor, capaz de analisar qualquer aspecto do seu funcionamento em tempo real.

---

## üéØ **Conceito 2: Os 3 Pilares da Observabilidade**

A observabilidade se apoia em tr√™s tipos principais de telemetria. Eles n√£o s√£o independentes; a m√°gica acontece quando eles est√£o **correlacionados**.

### **1. ü™µ Logs Estruturados**

Logs de texto plano (`System.out.println("Erro")`) s√£o in√∫teis em escala. **Logs Estruturados** (geralmente em JSON) s√£o a solu√ß√£o. Eles transformam cada linha de log em um objeto rico em dados que pode ser facilmente pesquisado, filtrado e agregado.

**Java (SLF4J + Logback):**
A melhor forma de fazer isso em Java √© usar uma biblioteca como `logstash-logback-encoder`.

```xml
<!-- pom.xml -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.2</version>
</dependency>
```

```xml
<!-- logback.xml -->
<configuration>
    <appender name="jsonConsoleAppender" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>

    <root level="INFO">
        <appender-ref ref="jsonConsoleAppender"/>
    </root>
</configuration>
```

```java
// No seu c√≥digo
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import static net.logstash.logback.argument.StructuredArguments.*;

@Service
public class PagamentoService {
    private static final Logger logger = LoggerFactory.getLogger(PagamentoService.class);

    public void processar(Pagamento pagamento) {
        logger.info(
            "Processando pagamento",
            kv("pagamentoId", pagamento.getId()),
            kv("clienteId", pagamento.getClienteId()),
            kv("valor", pagamento.getValor()),
            kv("moeda", "BRL")
        );
        // ...
    }
}
```

**Sa√≠da JSON (Pronta para o CloudWatch Logs Insights):**
```json
{
  "@timestamp": "2023-10-27T10:00:00.123Z",
  "@version": "1",
  "message": "Processando pagamento",
  "logger_name": "com.example.PagamentoService",
  "thread_name": "task-1",
  "level": "INFO",
  "pagamentoId": "pay_12345",
  "clienteId": "cli_67890",
  "valor": 99.90,
  "moeda": "BRL"
}
```

### **2. üìà M√©tricas (Metrics)**
M√©tricas s√£o agrega√ß√µes num√©ricas ao longo do tempo. Elas s√£o eficientes para armazenar e consultar, ideais para dashboards e alertas.

**Java (Micrometer):**
O Micrometer √© o `SLF4J` das m√©tricas. √â uma fachada que se integra com dezenas de sistemas de monitoramento (Prometheus, CloudWatch, Datadog). O Spring Boot Actuator o utiliza por padr√£o.

```java
// pom.xml com Spring Boot Actuator e suporte ao CloudWatch
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-cloudwatch2</artifactId>
</dependency>
```

```java
@Service
public class PedidoService {
    private final Counter pedidosCriadosCounter;
    private final Timer processamentoPedidoTimer;

    public PedidoService(MeterRegistry meterRegistry) {
        // M√©trica do tipo "Contador"
        this.pedidosCriadosCounter = meterRegistry.counter(
            "pedidos.criados.total",
            "tipo", "online" // "Tags" ou "Dimens√µes" permitem filtrar a m√©trica
        );
        // M√©trica do tipo "Timer" para medir lat√™ncia
        this.processamentoPedidoTimer = meterRegistry.timer("pedidos.processamento.latencia");
    }

    public void criarPedido(Pedido pedido) {
        processamentoPedidoTimer.record(() -> {
            // ... l√≥gica de neg√≥cio ...
            pedidosCriadosCounter.increment();
        });
    }
}
```
Essas m√©tricas podem ser enviadas automaticamente para o **AWS CloudWatch** para criar dashboards e alarmes.

### **3. Œπœá Traces (Rastreamentos Distribu√≠dos)**
Traces s√£o o pilar mais importante para depurar microservi√ßos. Um `trace` √© a hist√≥ria completa de uma requisi√ß√£o enquanto ela viaja por m√∫ltiplos servi√ßos. Cada `trace` √© composto por `spans`.

-   **Trace:** Representa a transa√ß√£o inteira. Possui um `traceId` √∫nico.
-   **Span:** Representa uma √∫nica unidade de trabalho dentro do trace (ex: uma chamada de API, uma query no banco). Possui um `spanId` e herda o `traceId`. Spans podem ter `spans` filhos.

Juntos, eles formam uma √°rvore que mostra exatamente onde o tempo foi gasto e onde os erros ocorreram.

---

## üéØ **Conceito 3: Implementando Tracing Distribu√≠do com OpenTelemetry e AWS X-Ray**

**OpenTelemetry (OTel)** √© uma iniciativa da Cloud Native Computing Foundation (CNCF) para padronizar a forma como coletamos e exportamos telemetria (traces, m√©tricas e logs). Ao usar OTel, voc√™ evita o *vendor lock-in*, podendo trocar o backend de observabilidade (de X-Ray para Datadog, por exemplo) com uma simples mudan√ßa de configura√ß√£o.

**AWS X-Ray** √© o servi√ßo de tracing distribu√≠do da AWS. Ele coleta dados sobre as requisi√ß√µes, constr√≥i um "mapa de servi√ßo" visual e ajuda a identificar gargalos de performance e erros.

### **Passo a Passo: Instrumentando uma Aplica√ß√£o Java**

#### **1. Adicionar Depend√™ncias do OpenTelemetry**

A forma mais f√°cil √© usar o **Agente Java do OpenTelemetry**. √â um √∫nico arquivo `.jar` que voc√™ anexa √† sua aplica√ß√£o na inicializa√ß√£o, sem precisar alterar seu c√≥digo. Ele instrumenta automaticamente bibliotecas populares (Spring, JDBC, Apache HttpClient, etc.).

```bash
# Exemplo de como iniciar sua aplica√ß√£o Java com o agente
java -javaagent:path/to/opentelemetry-javaagent.jar \
     -Dotel.service.name=meu-servico-de-pedidos \
     -Dotel.traces.exporter=otlp \
     -Dotel.exporter.otlp.protocol=http/protobuf \
     -Dotel.exporter.otlp.endpoint=http://localhost:4318 \
     -jar minha-aplicacao.jar
```
*Observa√ß√£o: O endpoint `localhost:4318` aponta para um **Coletor OpenTelemetry**, que veremos a seguir.*

#### **2. Coletar e Exportar Dados com o AWS Distro for OpenTelemetry (ADOT) Collector**

Voc√™ n√£o envia dados diretamente da sua aplica√ß√£o para o X-Ray. A melhor pr√°tica √© usar um **Coletor**. O **ADOT Collector** √© a implementa√ß√£o da AWS para o Coletor OTel. Ele roda como um servi√ßo separado (um sidecar em cont√™ineres ou um processo no EC2) e age como um "hub" de telemetria.

**Por que usar um Coletor?**
-   **Desacoplamento:** Sua aplica√ß√£o s√≥ precisa saber como enviar dados para o coletor local. O coletor cuida de autentica√ß√£o, retries e exporta√ß√£o para a AWS.
-   **Processamento:** O coletor pode enriquecer, filtrar ou agregar dados antes de export√°-los.
-   **Efici√™ncia:** Agrupa dados de m√∫ltiplas fontes e os envia em batch, otimizando custos e performance.

**Exemplo de configura√ß√£o do ADOT Collector (`collector.yaml`):**

```yaml
receivers:
  otlp: # Recebe dados da sua aplica√ß√£o via protocolo OTLP
    protocols:
      grpc:
      http:

processors:
  batch: # Agrupa dados em lotes para envio eficiente

exporters:
  awsxray: # Exportador que envia os traces para o AWS X-Ray
    region: "sa-east-1"
  awsemf: # Exportador que envia m√©tricas para o CloudWatch como Embedded Metric Format
    region: "sa-east-1"
    namespace: "MeuApp/Microsservicos"

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [awsxray] # Pipeline de traces: OTLP -> Batch -> X-Ray
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [awsemf] # Pipeline de m√©tricas: OTLP -> Batch -> CloudWatch EMF
```

Este coletor est√° configurado para receber traces e m√©tricas da sua aplica√ß√£o e export√°-los para X-Ray and CloudWatch, respectivamente.

#### **3. An√°lise Visual no AWS X-Ray**

Uma vez que os dados de trace chegam ao X-Ray, voc√™ obt√©m superpoderes:

-   **Mapa de Servi√ßo (Service Map):** Uma visualiza√ß√£o em tempo real de como seus servi√ßos se conectam, incluindo lat√™ncia m√©dia e taxas de erro para cada conex√£o.
    ![AWS X-Ray Service Map](https://miro.medium.com/max/1400/1*L8a5B4G8Xy7r9b3Z2A_f9w.png)

-   **An√°lise de Traces (Traces Analytics):** Voc√™ pode mergulhar em um trace individual para ver a "cascata" de chamadas (waterfall view), identificando exatamente qual span est√° lento ou retornando erro.
    ![AWS X-Ray Trace Waterfall](https://docs.aws.amazon.com/xray/latest/devguide/images/traces-console-timeline.png)

### **Correlacionando os 3 Pilares**

A verdadeira m√°gica acontece quando voc√™ conecta tudo. O OpenTelemetry faz isso injetando o `traceId` e o `spanId` automaticamente nos seus logs.

**Log Estruturado com `traceId`:**
```json
{
  "timestamp": "...",
  "level": "INFO",
  "message": "Processando pagamento",
  "pagamentoId": "pay_12345",
  "trace_id": "1-5f8f8b8a-1b1b1b1b1b1b1b1b1b1b1b1b", // <-- A M√ÅGICA!
  "span_id": "2c2c2c2c2c2c2c2c"
}
```
Com isso, dentro do X-Ray, voc√™ pode clicar em um span com erro e ver **exatamente os logs** gerados durante aquela opera√ß√£o espec√≠fica. No CloudWatch, voc√™ pode encontrar um log de erro e, usando o `trace_id`, pular diretamente para a visualiza√ß√£o completa do trace no X-Ray.

---

## üéØ **Conceito 4: Dashboards e Investiga√ß√µes Pr√°ticas no CloudWatch**

Coletar telemetria √© apenas metade do trabalho. A outra metade √© saber como visualiz√°-la e extrair insights pr√°ticos.

### **1. CloudWatch Logs Insights: O "SQL" para seus Logs**

O CloudWatch Logs Insights oferece uma linguagem de consulta poderosa para analisar seus logs estruturados em tempo real. √â a ferramenta mais importante para investiga√ß√µes de causa raiz.

**Cen√°rio:** *Houve um pico de erros no nosso servi√ßo de pagamento. Queremos saber quais clientes foram mais afetados e quais os tipos de erro.*

```sql
# Exemplo de Query no Logs Insights

# Campos que queremos exibir na tabela de resultados
fields @timestamp, @message, pagamentoId, clienteId, error.code
# Filtra logs do nosso servi√ßo, que sejam do n√≠vel ERROR, nos √∫ltimos 30 minutos
| filter logger_name == 'com.example.PagamentoService' and @logLevel == 'ERROR'
| filter @timestamp > now() - 30m
# Agrupa os resultados por tipo de erro e conta as ocorr√™ncias
| stats count(*) as totalErros by error.code
# Ordena para mostrar os erros mais comuns primeiro
| sort totalErros desc
```

**Resultado:**
Uma tabela mostrando exatamente quais c√≥digos de erro (`gateway_timeout`, `insufficient_funds`) aconteceram com mais frequ√™ncia, permitindo que voc√™ foque sua investiga√ß√£o.

### **2. Criando Dashboards Eficazes**

Um bom dashboard conta uma hist√≥ria. Evite dashboards com dezenas de gr√°ficos de CPU. Em vez disso, foque em m√©tricas que reflitam a **sa√∫de do neg√≥cio e a experi√™ncia do usu√°rio**.

**O M√©todo das 4 M√©tricas de Ouro (Google SRE):**
Um √≥timo ponto de partida para qualquer servi√ßo:

1.  **Lat√™ncia (Latency):** O tempo que leva para servir uma requisi√ß√£o. (Ex: `pedidos.processamento.latencia` do nosso exemplo com Micrometer).
2.  **Tr√°fego (Traffic):** A quantidade de demanda que seu sistema est√° recebendo. (Ex: Requisi√ß√µes por segundo, `pedidos.criados.total`).
3.  **Erros (Errors):** A taxa de requisi√ß√µes que est√£o falhando. (Ex: M√©trica de `http_server_requests` com `status=5xx`).
4.  **Satura√ß√£o (Saturation):** Qu√£o "cheio" seu servi√ßo est√°. Representa a utiliza√ß√£o do seu recurso mais restrito (CPU, mem√≥ria, I/O, tamanho da fila).

**Exemplo de Widget para um Dashboard no CloudWatch (Terraform):**

```terraform
resource "aws_cloudwatch_dashboard" "app_dashboard" {
  dashboard_name = "MinhaApp-VisaoGeral"

  dashboard_body = jsonencode({
    widgets = [
      {
        type   = "metric",
        width  = 12,
        height = 6,
        properties = {
          title  = "Lat√™ncia de Processamento de Pedidos (p95)",
          region = "sa-east-1",
          stat   = "p95", # O percentil 95 √© mais √∫til que a m√©dia!
          metrics = [
            ["MeuApp/Microsservicos", "pedidos.processamento.latencia", "ServiceName", "servico-de-pedidos"]
          ]
        }
      },
      {
        type   = "metric",
        width  = 12,
        height = 6,
        properties = {
          title  = "Taxa de Erros no Gateway (5xx)",
          region = "sa-east-1",
          stat   = "Sum",
          metrics = [
            ["AWS/ApiGateway", "5XXError", "ApiName", "meu-gateway"]
          ]
        }
      },
      {
        type = "log",
        width = 24,
        height = 8,
        properties = {
            title = "Logs de Erro Recentes (Pagamentos)",
            region = "sa-east-1",
            # Query do Logs Insights diretamente no dashboard!
            query = "SOURCE '/aws/lambda/servico-de-pagamentos' | fields @timestamp, @message | filter @logLevel = 'ERROR' | sort @timestamp desc | limit 20"
        }
      }
    ]
  })
}
```
Este dashboard simples j√° √© extremamente poderoso, pois mostra a **experi√™ncia do usu√°rio** (lat√™ncia), a **sa√∫de do sistema** (erros) e fornece **acesso direto aos logs de erro** para investiga√ß√£o imediata.

---

## üöÄ **Resumo do M√≥dulo e Pr√≥ximos Passos**

Neste m√≥dulo, voc√™ aprendeu que:
- Observabilidade √© sobre fazer perguntas, n√£o apenas ver pain√©is.
- Os 3 pilares (Logs, M√©tricas, Traces) s√£o a base de qualquer sistema observ√°vel.
- Logs devem ser **estruturados** para permitir consultas complexas.
- Tracing distribu√≠do com **OpenTelemetry** e **AWS X-Ray** √© essencial para depurar microservi√ßos.
- A m√°gica acontece quando os pilares s√£o **correlacionados** (ex: `traceId` nos logs).
- Dashboards devem focar em **m√©tricas de neg√≥cio e experi√™ncia do usu√°rio**, n√£o apenas em CPU/mem√≥ria.

O pr√≥ximo passo l√≥gico na sua jornada de especialista √© aprender a **testar** esses sistemas distribu√≠dos complexos. 